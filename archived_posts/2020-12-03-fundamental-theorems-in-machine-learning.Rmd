---
title: '"Fundamental" theorems in machine learning'
author: Yutong Wang
date: '2020-12-03'
slug: fundamental-theorems-in-machine-learning
categories: []
tags: []
---


There is a nice [article on fundamental theorems in mathematics](http://people.math.harvard.edu/~knill/graphgeometry/papers/fundamental.pdf) that I really enjoyed reading.
Sadly, the section on artificial intelligence only talked about a [joke "theorem" from The Big Lebowski](https://kottke.org/18/04/the-lebowski-theorem-of-machine-superintelligence).
This inspired me to list a few theorems that I personally find to be very pleasing and unifying.
The membership criterion for this list is that seeing the theorem should induce the same feeling as seeing this sight:
![](/post/2020-12-03-fundamental-theorems-in-machine-learning_files/640px-West_Mitten_Butte,_East_Mitten_Butte,_and_Merrick_Butte.jpg)


# Vapnik–Chervonenkis theory

- [Sauer-Shelah lemma](https://en.wikipedia.org/wiki/Sauer%E2%80%93Shelah_lemma).
Here is a [beautiful proof using distributive lattice theory](https://cse.buffalo.edu/~hungngo/classes/2010/711/lectures/sauer.pdf) creditted to Peter Frankl and
Janos Pach.

# Kernel methods

- [Moore–Aronszajn theorem](https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space#:~:text=The%20Moore%E2%80%93Aronszajn%20theorem%20goes,Moore.)

# Low rank approximation

- [Eckart–Young–Mirsky theorem](https://en.wikipedia.org/wiki/Low-rank_approximation#Proof_of_Eckart%E2%80%93Young%E2%80%93Mirsky_theorem_(for_Frobenius_norm))

# Spectral clustering

- [Davis-Kahan theorem](https://en.wikipedia.org/wiki/Eigengap)


# Saddle point problems

- [von Neumann's Minimax theorem](https://en.wikipedia.org/wiki/Minimax_theorem)

- [Sion's minimax theorem](https://en.wikipedia.org/wiki/Sion%27s_minimax_theorem)